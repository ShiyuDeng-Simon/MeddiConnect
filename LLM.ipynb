{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShiyuDeng-Simon/MeddiConnect/blob/main/LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LOHZspm1ql9-",
        "outputId": "26cb1d7b-df26-4616-c2dd-4e3e57493bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2Sl_vdWRuEKg",
        "outputId": "60ead906-0970-4de3-b79f-84537cd0af02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "The token `Colab` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Colab`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ucDa7sn1hv",
        "outputId": "a92a8812-4984-46ee-846f-a1ef3aefb7c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py:810: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "device = \"cuda\"\n",
        "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", use_auth_token=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, use_auth_token=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bXv7OgGjqeJC"
      },
      "outputs": [],
      "source": [
        "def generate_response(prompt, max_length=1000):\n",
        "    \"\"\"\n",
        "    Generates a response using the Llama model.\n",
        "\n",
        "    Args:\n",
        "      prompt (str): The input prompt text.\n",
        "      max_length (int): The maximum length of the generated response.\n",
        "\n",
        "    Returns:\n",
        "      str: The generated response text.\n",
        "    \"\"\"\n",
        "    formatted_prompt = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n{prompt}\\n<|start_header_id|>assistant<|end_header_id|>\\n\"\n",
        "\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "    generate_ids = model.generate(inputs.input_ids, max_length=max_length)\n",
        "    response = tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BGBoSYOkwGtr",
        "outputId": "d9abb776-cf05-40c7-dc07-e16579f146b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user\n",
            "What is the meaning of life?\n",
            "assistant\n",
            "The question of the meaning of life has puzzled philosophers, theologians, scientists, and everyday people for centuries. There is no one definitive answer, and different perspectives offer varying interpretations. Here are some of the most common approaches:\n",
            "\n",
            "**Philosophical perspectives:**\n",
            "\n",
            "1. **Existentialism**: Life has no inherent meaning; we create our own meaning through our choices and experiences.\n",
            "2. **Absurdism**: Life is inherently meaningless, but we must create our own purpose and meaning in the face of absurdity.\n",
            "3. **Utilitarianism**: The meaning of life is to maximize happiness and well-being for the greatest number of people.\n",
            "4. **Stoicism**: The meaning of life is to live in accordance with reason, virtue, and self-control.\n",
            "5. **Humanism**: The meaning of life is to cultivate human flourishing, happiness, and fulfillment.\n",
            "\n",
            "**Religious perspectives:**\n",
            "\n",
            "1. **Theism**: The meaning of life is to fulfill a divine plan or purpose, as ordained by a higher power.\n",
            "2. **Nihilism**: Life has no inherent meaning, and there is no divine plan or purpose.\n",
            "3. **Buddhism**: The meaning of life is to achieve enlightenment, liberation from suffering, and the end of the cycle of rebirth.\n",
            "4. **Christianity**: The meaning of life is to follow Jesus Christ and fulfill the commandments.\n",
            "5. **Hinduism**: The meaning of life is to achieve moksha (liberation from the cycle of birth and death) and self-realization.\n",
            "\n",
            "**Scientific perspectives:**\n",
            "\n",
            "1. **Biological perspective**: Life has an inherent purpose, which is to survive, reproduce, and perpetuate the species.\n",
            "2. **Evolutionary perspective**: Life is driven by the survival of the fittest, and the meaning of life is to adapt and evolve.\n",
            "3. **Cosmological perspective**: The meaning of life is to understand and appreciate the vastness and complexity of the universe.\n",
            "4. **Philosophical naturalism**: The meaning of life is to seek knowledge, understanding, and the pursuit of happiness.\n",
            "\n",
            "**Personal perspectives:**\n",
            "\n",
            "1. **Self-actualization**: The meaning of life is to realize one's full potential and live a fulfilling life.\n",
            "2. **Personal growth**: The meaning of life is to learn, grow, and become the best version of oneself.\n",
            "3. **Relationships**: The meaning of life is to build and nurture meaningful relationships with others.\n",
            "4. **Contribution**: The meaning of life is to contribute to the greater good and leave a positive impact on the world.\n",
            "\n",
            "Ultimately, the meaning of life is a deeply personal and subjective question that each individual must answer for themselves. What gives your life meaning is unique to you and your experiences, values, and goals.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"What is the meaning of life?\"\n",
        "response = generate_response(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6BJhgfKxCNh",
        "outputId": "4d7c9685-826c-4bda-fff4-fab8bd0f0565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate_endpoint():\n",
        "    \"\"\"\n",
        "    API endpoint to generate text based on provided prompt.\n",
        "    Expects a JSON POST request with a 'prompt' key.\n",
        "    Returns:\n",
        "        JSON response with a 'response' key.\n",
        "    \"\"\"\n",
        "    data = request.get_json()\n",
        "    if not data or 'prompt' not in data:\n",
        "        return jsonify({'error': 'Missing prompt in request body'}), 400\n",
        "    prompt = data['prompt']\n",
        "    try:\n",
        "        response = generate_response(prompt)\n",
        "        return jsonify({'response': response})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 500\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host='0.0.0.0', port=5000, debug=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKz8KK__1oFU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyN2Q8hCkWZ7v05F3Aljwn+8",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
